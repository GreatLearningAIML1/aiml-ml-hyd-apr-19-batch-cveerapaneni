{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I keep getting the Kernel died error. Hence the temporary fix for that is the below statement.\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "5ef9aff6-a7bd-4b26-cba6-8750955f6ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "# import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.astype(np.float32)\n",
    "testX = testX.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "87e1b9cd-07f0-45cb-e706-0d51ad742d72",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "ohTrainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "ohTestY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples in Train data now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(ohTrainY.shape)\n",
    "print('First 5 examples in Train data now are: ', ohTrainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "27bdfe58-91ee-4677-fe49-e742ad306c70",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "First 5 examples in Test data now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(ohTestY.shape)\n",
    "print('First 5 examples in Test data now are: ', ohTestY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for each of the above image :  [9 0 0 3 0 2 7 2 5 5]\n"
     ]
    }
   ],
   "source": [
    "# Image printing\n",
    "import matplotlib.pyplot as plt\n",
    "w=10\n",
    "h=10\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "columns = 10\n",
    "rows = 1\n",
    "for i in range(1, columns*rows + 1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(trainX[i-1], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Label for each of the above image : ', trainY[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "# Output Layer with 10 neurons\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59C_-IgOIVB",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 9.6707 - acc: 0.1408 - val_loss: 10.0068 - val_acc: 0.1437\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.7974 - acc: 0.1514 - val_loss: 9.3230 - val_acc: 0.1569\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.3484 - acc: 0.1595 - val_loss: 10.2513 - val_acc: 0.1613\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.4910 - acc: 0.1633 - val_loss: 9.2261 - val_acc: 0.1654\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.6425 - acc: 0.1657 - val_loss: 9.4534 - val_acc: 0.1673\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.6758 - acc: 0.1658 - val_loss: 9.2728 - val_acc: 0.1682\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.6900 - acc: 0.1667 - val_loss: 9.6822 - val_acc: 0.1671\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 9.8855 - acc: 0.1667 - val_loss: 9.9450 - val_acc: 0.1680\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.8178 - acc: 0.1672 - val_loss: 9.9433 - val_acc: 0.1680\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.7531 - acc: 0.1674 - val_loss: 9.1261 - val_acc: 0.1686\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 9.5613 - acc: 0.1673 - val_loss: 9.8627 - val_acc: 0.1687\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1217 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: nan - acc: 0.1000 - val_loss: nan - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3ca76e48>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, ohTrainY, validation_data=(testX,ohTestY), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model1 = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape\n",
    "model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "# Normalize the data\n",
    "model1.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Output Layer with 10 neurons\n",
    "model1.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "# Model compilation\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLR8tcBOIVP",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 6.2059 - acc: 0.2035 - val_loss: 8.2563 - val_acc: 0.2009\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.0394 - acc: 0.2126 - val_loss: 8.4951 - val_acc: 0.2477\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 8.0039 - acc: 0.2609 - val_loss: 7.0618 - val_acc: 0.2649\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 6.8368 - acc: 0.2075 - val_loss: 6.3456 - val_acc: 0.1659\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.5103 - acc: 0.1484 - val_loss: 6.7678 - val_acc: 0.1840\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.3501 - acc: 0.1748 - val_loss: 7.8244 - val_acc: 0.1753\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 8.2989 - acc: 0.2316 - val_loss: 7.9862 - val_acc: 0.2440\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.8623 - acc: 0.2395 - val_loss: 7.2807 - val_acc: 0.2208\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.9175 - acc: 0.2245 - val_loss: 7.5643 - val_acc: 0.1884\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.2634 - acc: 0.1854 - val_loss: 6.7728 - val_acc: 0.1812\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 6.7135 - acc: 0.1777 - val_loss: 5.9948 - val_acc: 0.1474\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 6.3583 - acc: 0.1430 - val_loss: 6.9459 - val_acc: 0.1007\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.8852 - acc: 0.1169 - val_loss: 5.5917 - val_acc: 0.1215\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.5852 - acc: 0.1216 - val_loss: 5.4781 - val_acc: 0.1259\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.4914 - acc: 0.1255 - val_loss: 5.4010 - val_acc: 0.1286\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.4374 - acc: 0.1272 - val_loss: 5.3524 - val_acc: 0.1316\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.3723 - acc: 0.1288 - val_loss: 5.3189 - val_acc: 0.1319\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.3260 - acc: 0.1314 - val_loss: 5.2757 - val_acc: 0.1353\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 5.2870 - acc: 0.1341 - val_loss: 5.2280 - val_acc: 0.1377\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.2336 - acc: 0.1371 - val_loss: 5.1982 - val_acc: 0.1406\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 5.1867 - acc: 0.1404 - val_loss: 5.1565 - val_acc: 0.1422\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.1382 - acc: 0.1431 - val_loss: 5.0995 - val_acc: 0.1458\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 5.0893 - acc: 0.1457 - val_loss: 5.0655 - val_acc: 0.1471\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 5.0483 - acc: 0.1474 - val_loss: 5.0310 - val_acc: 0.1495\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.9665 - acc: 0.1525 - val_loss: 4.9376 - val_acc: 0.1575\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.9062 - acc: 0.1574 - val_loss: 4.9046 - val_acc: 0.1582\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 4.8694 - acc: 0.1732 - val_loss: 4.8654 - val_acc: 0.1862\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 4.8324 - acc: 0.1846 - val_loss: 4.8455 - val_acc: 0.1867\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.8113 - acc: 0.1844 - val_loss: 4.8239 - val_acc: 0.1855\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 4.7874 - acc: 0.1842 - val_loss: 4.7946 - val_acc: 0.1848\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.7657 - acc: 0.1837 - val_loss: 4.7785 - val_acc: 0.1846\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.7540 - acc: 0.1835 - val_loss: 4.7562 - val_acc: 0.1848\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.7314 - acc: 0.1834 - val_loss: 4.7388 - val_acc: 0.1846\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.7165 - acc: 0.1835 - val_loss: 4.7224 - val_acc: 0.1843\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.6955 - acc: 0.1836 - val_loss: 4.7038 - val_acc: 0.1851\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.6771 - acc: 0.1829 - val_loss: 4.7023 - val_acc: 0.1852\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.6548 - acc: 0.1830 - val_loss: 4.6759 - val_acc: 0.1852\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.6365 - acc: 0.1837 - val_loss: 4.6575 - val_acc: 0.1848\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.6233 - acc: 0.1830 - val_loss: 4.6438 - val_acc: 0.1853\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.6023 - acc: 0.1836 - val_loss: 4.6044 - val_acc: 0.1849\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 4.5871 - acc: 0.1834 - val_loss: 4.5744 - val_acc: 0.1845\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.5622 - acc: 0.1867 - val_loss: 4.5594 - val_acc: 0.1888\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 4.5391 - acc: 0.1875 - val_loss: 4.5373 - val_acc: 0.1909\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.5132 - acc: 0.1893 - val_loss: 4.5090 - val_acc: 0.1911\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 4.5121 - acc: 0.1915 - val_loss: 4.4912 - val_acc: 0.1932\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.4854 - acc: 0.1914 - val_loss: 4.5049 - val_acc: 0.1913\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.4863 - acc: 0.1934 - val_loss: 4.4961 - val_acc: 0.1969\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.4522 - acc: 0.1960 - val_loss: 4.4709 - val_acc: 0.2013\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.4678 - acc: 0.2042 - val_loss: 4.4358 - val_acc: 0.2100\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 4.4301 - acc: 0.2177 - val_loss: 4.3705 - val_acc: 0.2359\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 4.4463 - acc: 0.2504 - val_loss: 4.3442 - val_acc: 0.2846\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 4.5546 - acc: 0.2909 - val_loss: 4.5625 - val_acc: 0.3250\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 4.9394 - acc: 0.3149 - val_loss: 5.0785 - val_acc: 0.3348\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 5.5943 - acc: 0.3217 - val_loss: 5.7971 - val_acc: 0.3373\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 6.1151 - acc: 0.3262 - val_loss: 5.7820 - val_acc: 0.3405\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 6.3865 - acc: 0.3292 - val_loss: 6.7541 - val_acc: 0.3364\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 7.1853 - acc: 0.3279 - val_loss: 7.5250 - val_acc: 0.3409\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 110us/sample - loss: 7.4876 - acc: 0.3290 - val_loss: 7.8971 - val_acc: 0.3456\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 8.0543 - acc: 0.3288 - val_loss: 8.4078 - val_acc: 0.3399\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 8.3791 - acc: 0.3257 - val_loss: 8.2810 - val_acc: 0.3428\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 8.1780 - acc: 0.3304 - val_loss: 8.4628 - val_acc: 0.3400\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 8.4246 - acc: 0.3288 - val_loss: 8.5830 - val_acc: 0.3392\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.5346 - acc: 0.3271 - val_loss: 8.6650 - val_acc: 0.3423\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 8.7189 - acc: 0.3246 - val_loss: 8.7745 - val_acc: 0.3380\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 8.8526 - acc: 0.3238 - val_loss: 8.8878 - val_acc: 0.3349\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 8.9338 - acc: 0.3215 - val_loss: 9.0358 - val_acc: 0.3350\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 9.0459 - acc: 0.3201 - val_loss: 9.0580 - val_acc: 0.3298\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 9.1585 - acc: 0.3178 - val_loss: 9.2211 - val_acc: 0.3284\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 9.2344 - acc: 0.3143 - val_loss: 9.2845 - val_acc: 0.3256\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 9.3954 - acc: 0.3094 - val_loss: 10.7861 - val_acc: 0.3048\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 10.6580 - acc: 0.2868 - val_loss: 10.5215 - val_acc: 0.3036\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 10.3925 - acc: 0.2838 - val_loss: 10.2399 - val_acc: 0.2974\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 10.1428 - acc: 0.2807 - val_loss: 9.9867 - val_acc: 0.2950\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 9.9691 - acc: 0.2785 - val_loss: 9.8349 - val_acc: 0.2951\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 9.8283 - acc: 0.2790 - val_loss: 9.7919 - val_acc: 0.2951\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 7.5637 - acc: 0.3081 - val_loss: 6.7711 - val_acc: 0.3361\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.9499 - acc: 0.3239 - val_loss: 6.9449 - val_acc: 0.3358\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.4103 - acc: 0.3253 - val_loss: 7.3832 - val_acc: 0.3356\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.8228 - acc: 0.3275 - val_loss: 7.8506 - val_acc: 0.3363\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.4280 - acc: 0.3241 - val_loss: 8.7914 - val_acc: 0.3338\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 8.9286 - acc: 0.3219 - val_loss: 9.1427 - val_acc: 0.3320\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 9.4044 - acc: 0.3189 - val_loss: 9.4135 - val_acc: 0.3264\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 9.6598 - acc: 0.3128 - val_loss: 9.8370 - val_acc: 0.3249\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 9.7515 - acc: 0.3103 - val_loss: 9.7718 - val_acc: 0.3203\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 9.6925 - acc: 0.3106 - val_loss: 9.7563 - val_acc: 0.3266\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 9.5642 - acc: 0.3114 - val_loss: 9.4736 - val_acc: 0.3248\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 9.3956 - acc: 0.3115 - val_loss: 9.4000 - val_acc: 0.3193\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 9.2705 - acc: 0.3064 - val_loss: 9.1729 - val_acc: 0.3153\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 9.1001 - acc: 0.3029 - val_loss: 9.0874 - val_acc: 0.3115\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.9601 - acc: 0.3000 - val_loss: 8.9866 - val_acc: 0.3108\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.8068 - acc: 0.2946 - val_loss: 8.7885 - val_acc: 0.3038\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.6441 - acc: 0.2910 - val_loss: 8.6552 - val_acc: 0.3029\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.5122 - acc: 0.2897 - val_loss: 8.5662 - val_acc: 0.2979\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 8.4237 - acc: 0.2830 - val_loss: 8.3606 - val_acc: 0.2949\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.3386 - acc: 0.2794 - val_loss: 8.3524 - val_acc: 0.2910\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 8.2203 - acc: 0.2737 - val_loss: 8.2770 - val_acc: 0.2864\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 8.1928 - acc: 0.2702 - val_loss: 8.0872 - val_acc: 0.2838\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.9388 - acc: 0.2680 - val_loss: 7.8129 - val_acc: 0.2846\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.7748 - acc: 0.2648 - val_loss: 7.5595 - val_acc: 0.2836\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.5685 - acc: 0.2617 - val_loss: 7.2865 - val_acc: 0.2787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3ead4b00>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(trainX, ohTrainY, validation_data=(testX,ohTestY), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 7.4622 - acc: 0.2617 - val_loss: 7.2615 - val_acc: 0.2801\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.4295 - acc: 0.2590 - val_loss: 7.2614 - val_acc: 0.2801\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.4138 - acc: 0.2586 - val_loss: 7.2489 - val_acc: 0.2799\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.3918 - acc: 0.2602 - val_loss: 7.2776 - val_acc: 0.2789\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.3734 - acc: 0.2594 - val_loss: 7.2497 - val_acc: 0.2792\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.3748 - acc: 0.2592 - val_loss: 7.2201 - val_acc: 0.2788\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.4028 - acc: 0.2574 - val_loss: 7.2561 - val_acc: 0.2794\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.3473 - acc: 0.2570 - val_loss: 7.2573 - val_acc: 0.2752\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.3268 - acc: 0.2571 - val_loss: 7.2365 - val_acc: 0.2770\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.3404 - acc: 0.2569 - val_loss: 7.2355 - val_acc: 0.2795\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.3258 - acc: 0.2558 - val_loss: 7.2160 - val_acc: 0.2736\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.2652 - acc: 0.2559 - val_loss: 7.2226 - val_acc: 0.2768\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.2921 - acc: 0.2547 - val_loss: 7.1977 - val_acc: 0.2772\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.2967 - acc: 0.2556 - val_loss: 7.1833 - val_acc: 0.2755\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.2685 - acc: 0.2551 - val_loss: 7.1921 - val_acc: 0.2718\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.2710 - acc: 0.2550 - val_loss: 7.1578 - val_acc: 0.2749\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.2465 - acc: 0.2541 - val_loss: 7.1617 - val_acc: 0.2754\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 7.2526 - acc: 0.2530 - val_loss: 7.1400 - val_acc: 0.2737\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.2255 - acc: 0.2552 - val_loss: 7.1206 - val_acc: 0.2735\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.1710 - acc: 0.2531 - val_loss: 7.1000 - val_acc: 0.2758\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 7.1143 - acc: 0.2522 - val_loss: 6.9465 - val_acc: 0.2731\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.8241 - acc: 0.2476 - val_loss: 6.7280 - val_acc: 0.2675\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.7576 - acc: 0.2464 - val_loss: 6.6138 - val_acc: 0.2661\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.7158 - acc: 0.2457 - val_loss: 6.6065 - val_acc: 0.2678\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.7165 - acc: 0.2450 - val_loss: 6.5699 - val_acc: 0.2700\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.6927 - acc: 0.2444 - val_loss: 6.4953 - val_acc: 0.2692\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.6760 - acc: 0.2440 - val_loss: 6.5148 - val_acc: 0.2640\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.5849 - acc: 0.2439 - val_loss: 6.4263 - val_acc: 0.2674\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.6057 - acc: 0.2435 - val_loss: 6.4121 - val_acc: 0.2698\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.5654 - acc: 0.2429 - val_loss: 6.3463 - val_acc: 0.2642\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.5612 - acc: 0.2429 - val_loss: 6.3364 - val_acc: 0.2676\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 6.5340 - acc: 0.2427 - val_loss: 6.3291 - val_acc: 0.2627\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.5920 - acc: 0.2403 - val_loss: 6.3790 - val_acc: 0.2632\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 6.5745 - acc: 0.2402 - val_loss: 6.3607 - val_acc: 0.2605\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.5902 - acc: 0.2390 - val_loss: 6.3557 - val_acc: 0.2660\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.5526 - acc: 0.2379 - val_loss: 6.3677 - val_acc: 0.2640\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.5352 - acc: 0.2390 - val_loss: 6.3487 - val_acc: 0.2595\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.5189 - acc: 0.2378 - val_loss: 6.3350 - val_acc: 0.2607\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.5188 - acc: 0.2368 - val_loss: 6.3305 - val_acc: 0.2586\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.5104 - acc: 0.2379 - val_loss: 6.3352 - val_acc: 0.2619\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4964 - acc: 0.2371 - val_loss: 6.3105 - val_acc: 0.2573\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4981 - acc: 0.2370 - val_loss: 6.3214 - val_acc: 0.2597\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4906 - acc: 0.2355 - val_loss: 6.3049 - val_acc: 0.2528\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4566 - acc: 0.2339 - val_loss: 6.2801 - val_acc: 0.2532\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4404 - acc: 0.2341 - val_loss: 6.2794 - val_acc: 0.2594\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4644 - acc: 0.2340 - val_loss: 6.3295 - val_acc: 0.2542\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4512 - acc: 0.2323 - val_loss: 6.3017 - val_acc: 0.2558\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4605 - acc: 0.2323 - val_loss: 6.3003 - val_acc: 0.2547\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4404 - acc: 0.2330 - val_loss: 6.3073 - val_acc: 0.2548\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4262 - acc: 0.2324 - val_loss: 6.3128 - val_acc: 0.2507\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4061 - acc: 0.2317 - val_loss: 6.3317 - val_acc: 0.2541\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4100 - acc: 0.2324 - val_loss: 6.3188 - val_acc: 0.2490\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4120 - acc: 0.2305 - val_loss: 6.2832 - val_acc: 0.2462\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4032 - acc: 0.2304 - val_loss: 6.2953 - val_acc: 0.2525\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4147 - acc: 0.2296 - val_loss: 6.2651 - val_acc: 0.2484\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4185 - acc: 0.2298 - val_loss: 6.2851 - val_acc: 0.2537\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4086 - acc: 0.2315 - val_loss: 6.2690 - val_acc: 0.2482\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.3834 - acc: 0.2285 - val_loss: 6.2626 - val_acc: 0.2464\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.3907 - acc: 0.2274 - val_loss: 6.2815 - val_acc: 0.2521\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4340 - acc: 0.2277 - val_loss: 6.2840 - val_acc: 0.2585\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 6.4003 - acc: 0.2274 - val_loss: 6.2995 - val_acc: 0.2499\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4190 - acc: 0.2273 - val_loss: 6.3090 - val_acc: 0.2438\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 6.4229 - acc: 0.2265 - val_loss: 6.2898 - val_acc: 0.2481\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 6.4122 - acc: 0.2262 - val_loss: 6.3072 - val_acc: 0.2531\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4075 - acc: 0.2272 - val_loss: 6.2931 - val_acc: 0.2456\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.3848 - acc: 0.2251 - val_loss: 6.3347 - val_acc: 0.2484\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 6.4100 - acc: 0.2262 - val_loss: 6.3227 - val_acc: 0.2445\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4207 - acc: 0.2238 - val_loss: 6.3425 - val_acc: 0.2438\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.3815 - acc: 0.2250 - val_loss: 6.3628 - val_acc: 0.2512\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4018 - acc: 0.2251 - val_loss: 6.3536 - val_acc: 0.2453\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4272 - acc: 0.2236 - val_loss: 6.3394 - val_acc: 0.2468\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.3956 - acc: 0.2246 - val_loss: 6.3519 - val_acc: 0.2431\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4051 - acc: 0.2223 - val_loss: 6.3851 - val_acc: 0.2433\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4170 - acc: 0.2242 - val_loss: 6.3709 - val_acc: 0.2513\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 6.3993 - acc: 0.2221 - val_loss: 6.3779 - val_acc: 0.2479\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4154 - acc: 0.2232 - val_loss: 6.3664 - val_acc: 0.2404\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 6.4112 - acc: 0.2221 - val_loss: 6.3768 - val_acc: 0.2472\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.3921 - acc: 0.2225 - val_loss: 6.3872 - val_acc: 0.2449\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4073 - acc: 0.2232 - val_loss: 6.3888 - val_acc: 0.2454\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4301 - acc: 0.2219 - val_loss: 6.3959 - val_acc: 0.2518\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 6.4281 - acc: 0.2225 - val_loss: 6.4003 - val_acc: 0.2445\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4403 - acc: 0.2227 - val_loss: 6.4218 - val_acc: 0.2433\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4258 - acc: 0.2211 - val_loss: 6.4285 - val_acc: 0.2455\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4298 - acc: 0.2199 - val_loss: 6.4058 - val_acc: 0.2443\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4495 - acc: 0.2204 - val_loss: 6.4271 - val_acc: 0.2460\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4335 - acc: 0.2212 - val_loss: 6.4403 - val_acc: 0.2437\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4415 - acc: 0.2204 - val_loss: 6.3824 - val_acc: 0.2412\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4586 - acc: 0.2217 - val_loss: 6.4019 - val_acc: 0.2486\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4505 - acc: 0.2221 - val_loss: 6.4066 - val_acc: 0.2510\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4649 - acc: 0.2210 - val_loss: 6.3973 - val_acc: 0.2455\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 6.4779 - acc: 0.2219 - val_loss: 6.3950 - val_acc: 0.2450\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4276 - acc: 0.2211 - val_loss: 6.4272 - val_acc: 0.2411\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4551 - acc: 0.2209 - val_loss: 6.4213 - val_acc: 0.2368\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4388 - acc: 0.2210 - val_loss: 6.4141 - val_acc: 0.2387\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4288 - acc: 0.2218 - val_loss: 6.4132 - val_acc: 0.2450\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 6.4719 - acc: 0.2200 - val_loss: 6.3896 - val_acc: 0.2401\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4323 - acc: 0.2206 - val_loss: 6.3842 - val_acc: 0.2428\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4288 - acc: 0.2196 - val_loss: 6.3592 - val_acc: 0.2416\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4293 - acc: 0.2214 - val_loss: 6.3543 - val_acc: 0.2409\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 6.4218 - acc: 0.2203 - val_loss: 6.3340 - val_acc: 0.2446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3e85de48>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model1.fit(trainX, ohTrainY, validation_data=(testX,ohTestY), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape\n",
    "model2.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "# Normalize the data\n",
    "model2.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "# 1st Dense Layer\n",
    "model2.add(tf.keras.layers.Dense(100, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": [
    "# 2nd Dense Layer\n",
    "model2.add(tf.keras.layers.Dense(100, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP7IL52OIVw"
   },
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
    "model2.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_9 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 92,746\n",
      "Trainable params: 91,178\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 1.0568 - acc: 0.6841 - val_loss: 0.6355 - val_acc: 0.7787\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.5667 - acc: 0.7996 - val_loss: 0.5106 - val_acc: 0.8148\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.4855 - acc: 0.8278 - val_loss: 0.4683 - val_acc: 0.8307\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.4518 - acc: 0.8389 - val_loss: 0.4448 - val_acc: 0.8377\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.4283 - acc: 0.8472 - val_loss: 0.4308 - val_acc: 0.8419\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.4128 - acc: 0.8530 - val_loss: 0.4170 - val_acc: 0.8478\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3962 - acc: 0.8587 - val_loss: 0.4065 - val_acc: 0.8500\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3860 - acc: 0.8624 - val_loss: 0.3987 - val_acc: 0.8552\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3767 - acc: 0.8645 - val_loss: 0.3927 - val_acc: 0.8561\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3659 - acc: 0.8679 - val_loss: 0.3891 - val_acc: 0.8575\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3588 - acc: 0.8702 - val_loss: 0.3788 - val_acc: 0.8625\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3503 - acc: 0.8744 - val_loss: 0.3714 - val_acc: 0.8651\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3426 - acc: 0.8747 - val_loss: 0.3658 - val_acc: 0.8666\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3374 - acc: 0.8784 - val_loss: 0.3630 - val_acc: 0.8683\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3309 - acc: 0.8805 - val_loss: 0.3668 - val_acc: 0.8651\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3242 - acc: 0.8831 - val_loss: 0.3595 - val_acc: 0.8658\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3180 - acc: 0.8854 - val_loss: 0.3565 - val_acc: 0.8683\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3114 - acc: 0.8877 - val_loss: 0.3506 - val_acc: 0.8733\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.3060 - acc: 0.8895 - val_loss: 0.3468 - val_acc: 0.8747\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3013 - acc: 0.8902 - val_loss: 0.3483 - val_acc: 0.8717\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2970 - acc: 0.8930 - val_loss: 0.3444 - val_acc: 0.8742\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2932 - acc: 0.8931 - val_loss: 0.3416 - val_acc: 0.8749\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2880 - acc: 0.8951 - val_loss: 0.3484 - val_acc: 0.8737\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2842 - acc: 0.8967 - val_loss: 0.3440 - val_acc: 0.8733\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2776 - acc: 0.8995 - val_loss: 0.3383 - val_acc: 0.8761\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2726 - acc: 0.8998 - val_loss: 0.3354 - val_acc: 0.8781\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.2711 - acc: 0.9013 - val_loss: 0.3368 - val_acc: 0.8792\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2660 - acc: 0.9030 - val_loss: 0.3339 - val_acc: 0.8797\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2612 - acc: 0.9053 - val_loss: 0.3322 - val_acc: 0.8815\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2575 - acc: 0.9061 - val_loss: 0.3360 - val_acc: 0.8781\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2538 - acc: 0.9071 - val_loss: 0.3319 - val_acc: 0.8814\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2503 - acc: 0.9088 - val_loss: 0.3290 - val_acc: 0.8822\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.2470 - acc: 0.9114 - val_loss: 0.3316 - val_acc: 0.8806\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2425 - acc: 0.9123 - val_loss: 0.3345 - val_acc: 0.8807\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2383 - acc: 0.9140 - val_loss: 0.3264 - val_acc: 0.8833\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2390 - acc: 0.9123 - val_loss: 0.3285 - val_acc: 0.8846\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2341 - acc: 0.9152 - val_loss: 0.3304 - val_acc: 0.8833\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2305 - acc: 0.9175 - val_loss: 0.3269 - val_acc: 0.8825\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2287 - acc: 0.9160 - val_loss: 0.3271 - val_acc: 0.8842\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2253 - acc: 0.9179 - val_loss: 0.3308 - val_acc: 0.8829\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.2193 - acc: 0.9200 - val_loss: 0.3329 - val_acc: 0.8841\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.2181 - acc: 0.9201 - val_loss: 0.3334 - val_acc: 0.8801\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.2158 - acc: 0.9215 - val_loss: 0.3361 - val_acc: 0.8822\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2136 - acc: 0.9222 - val_loss: 0.3312 - val_acc: 0.8833\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.2087 - acc: 0.9240 - val_loss: 0.3414 - val_acc: 0.8798\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2077 - acc: 0.9239 - val_loss: 0.3407 - val_acc: 0.8793\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.2059 - acc: 0.9240 - val_loss: 0.3348 - val_acc: 0.8831\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2013 - acc: 0.9261 - val_loss: 0.3366 - val_acc: 0.8844\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1986 - acc: 0.9270 - val_loss: 0.3352 - val_acc: 0.8855\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1971 - acc: 0.9280 - val_loss: 0.3348 - val_acc: 0.8835\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1946 - acc: 0.9288 - val_loss: 0.3424 - val_acc: 0.8826\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1924 - acc: 0.9301 - val_loss: 0.3355 - val_acc: 0.8847\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1904 - acc: 0.9307 - val_loss: 0.3425 - val_acc: 0.8834\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1861 - acc: 0.9329 - val_loss: 0.3423 - val_acc: 0.8828\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1866 - acc: 0.9316 - val_loss: 0.3346 - val_acc: 0.8863\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1825 - acc: 0.9329 - val_loss: 0.3380 - val_acc: 0.8858\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1790 - acc: 0.9337 - val_loss: 0.3405 - val_acc: 0.8835\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1792 - acc: 0.9342 - val_loss: 0.3446 - val_acc: 0.8841\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1770 - acc: 0.9349 - val_loss: 0.3508 - val_acc: 0.8853\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1742 - acc: 0.9356 - val_loss: 0.3425 - val_acc: 0.8875\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1717 - acc: 0.9358 - val_loss: 0.3461 - val_acc: 0.8845\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1692 - acc: 0.9378 - val_loss: 0.3456 - val_acc: 0.8861\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1677 - acc: 0.9384 - val_loss: 0.3509 - val_acc: 0.8840\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1685 - acc: 0.9381 - val_loss: 0.3504 - val_acc: 0.8853\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1629 - acc: 0.9414 - val_loss: 0.3474 - val_acc: 0.8875\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1632 - acc: 0.9409 - val_loss: 0.3720 - val_acc: 0.8812\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1608 - acc: 0.9406 - val_loss: 0.3628 - val_acc: 0.8835\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1612 - acc: 0.9406 - val_loss: 0.3535 - val_acc: 0.8846\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1584 - acc: 0.9430 - val_loss: 0.3667 - val_acc: 0.8835\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1565 - acc: 0.9430 - val_loss: 0.3594 - val_acc: 0.8856\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1571 - acc: 0.9430 - val_loss: 0.3658 - val_acc: 0.8827\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1535 - acc: 0.9432 - val_loss: 0.3589 - val_acc: 0.8843\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1504 - acc: 0.9457 - val_loss: 0.3694 - val_acc: 0.8808\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1520 - acc: 0.9439 - val_loss: 0.3656 - val_acc: 0.8842\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1485 - acc: 0.9452 - val_loss: 0.3689 - val_acc: 0.8845\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1461 - acc: 0.9472 - val_loss: 0.3615 - val_acc: 0.8825\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1455 - acc: 0.9473 - val_loss: 0.3761 - val_acc: 0.8827\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1439 - acc: 0.9478 - val_loss: 0.3748 - val_acc: 0.8858\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1438 - acc: 0.9482 - val_loss: 0.3723 - val_acc: 0.8824\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1420 - acc: 0.9475 - val_loss: 0.3776 - val_acc: 0.8827\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1400 - acc: 0.9487 - val_loss: 0.3803 - val_acc: 0.8828\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1376 - acc: 0.9500 - val_loss: 0.3791 - val_acc: 0.8817\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1345 - acc: 0.9505 - val_loss: 0.3785 - val_acc: 0.8819\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1344 - acc: 0.9515 - val_loss: 0.3869 - val_acc: 0.8815\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1342 - acc: 0.9509 - val_loss: 0.3833 - val_acc: 0.8827\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1333 - acc: 0.9523 - val_loss: 0.3871 - val_acc: 0.8835\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1323 - acc: 0.9508 - val_loss: 0.3844 - val_acc: 0.8773\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1304 - acc: 0.9522 - val_loss: 0.3821 - val_acc: 0.8848\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1279 - acc: 0.9522 - val_loss: 0.3876 - val_acc: 0.8794\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1307 - acc: 0.9522 - val_loss: 0.4077 - val_acc: 0.8788\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1292 - acc: 0.9523 - val_loss: 0.3889 - val_acc: 0.8805\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1267 - acc: 0.9541 - val_loss: 0.3965 - val_acc: 0.8837\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1264 - acc: 0.9537 - val_loss: 0.3972 - val_acc: 0.8826\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1253 - acc: 0.9544 - val_loss: 0.3886 - val_acc: 0.8823\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.1226 - acc: 0.9560 - val_loss: 0.4007 - val_acc: 0.8794\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1245 - acc: 0.9541 - val_loss: 0.3979 - val_acc: 0.8850\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1218 - acc: 0.9561 - val_loss: 0.4060 - val_acc: 0.8823\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.1211 - acc: 0.9556 - val_loss: 0.4062 - val_acc: 0.8776\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1183 - acc: 0.9574 - val_loss: 0.4047 - val_acc: 0.8828\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1208 - acc: 0.9565 - val_loss: 0.4237 - val_acc: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1061a5978>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(trainX, ohTrainY, validation_data=(testX,ohTestY), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification prediction for test data at position [15] = 1\n",
      "Classification prediction for test data at position [16] = 2\n",
      "Classification prediction for test data at position [17] = 2\n",
      "Classification prediction for test data at position [18] = 8\n",
      "Classification prediction for test data at position [19] = 0\n"
     ]
    }
   ],
   "source": [
    "pred = model2.predict(testX[15:20])\n",
    "pred\n",
    "\n",
    "initial = 15\n",
    "for i in range(len(pred)):\n",
    "    print('Classification prediction for test data at position [{}] = {}'.format(initial, np.argmax(pred[i])))\n",
    "    initial = initial + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for each of the above image :  [1 2 4 8 0]\n"
     ]
    }
   ],
   "source": [
    "# Image printing\n",
    "import matplotlib.pyplot as plt\n",
    "w=10\n",
    "h=10\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "columns = 5\n",
    "rows = 1\n",
    "testDataIndex = 15\n",
    "for i in range(1, columns*rows + 1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(testX[testDataIndex], cmap='gray')\n",
    "    testDataIndex = testDataIndex + 1\n",
    "plt.show()\n",
    "\n",
    "print('Label for each of the above image : ', testY[15:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classification_F-MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
